{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hxl/miniconda/envs/store-sales/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "# Read the data\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "holidays_events = pd.read_csv(\"data/holidays_events.csv\")\n",
    "oil = pd.read_csv(\"data/oil.csv\")\n",
    "stores = pd.read_csv(\"data/stores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/ld3hdqzj3d7840n3yw1hgcjc0000gn/T/ipykernel_13174/3227626489.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  holidays.rename(columns={\"date\": \"ds\", \"type\": \"holiday\"}, inplace=True)\n",
      "/var/folders/g6/ld3hdqzj3d7840n3yw1hgcjc0000gn/T/ipykernel_13174/3227626489.py:18: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train[\"dcoilwtico\"].fillna(method=\"ffill\", inplace=True)\n",
      "/var/folders/g6/ld3hdqzj3d7840n3yw1hgcjc0000gn/T/ipykernel_13174/3227626489.py:19: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test[\"dcoilwtico\"].fillna(method=\"ffill\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# Convert date columns to datetime\n",
    "train[\"date\"] = pd.to_datetime(train[\"date\"])\n",
    "test[\"date\"] = pd.to_datetime(test[\"date\"])\n",
    "holidays_events[\"date\"] = pd.to_datetime(holidays_events[\"date\"])\n",
    "oil[\"date\"] = pd.to_datetime(oil[\"date\"])\n",
    "\n",
    "# Create a holidays dataframe for Prophet\n",
    "holidays = holidays_events[[\"date\", \"type\"]]\n",
    "holidays.rename(columns={\"date\": \"ds\", \"type\": \"holiday\"}, inplace=True)\n",
    "\n",
    "# Merge oil prices into train and test data\n",
    "train = train.merge(oil, on=\"date\", how=\"left\")\n",
    "test = test.merge(oil, on=\"date\", how=\"left\")\n",
    "\n",
    "# Feature Engineering\n",
    "# Fill missing oil prices with the nearest available values\n",
    "train[\"dcoilwtico\"].fillna(method=\"ffill\", inplace=True)\n",
    "test[\"dcoilwtico\"].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "# Create a binary feature for promotions\n",
    "train[\"promotion\"] = train[\"onpromotion\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "test[\"promotion\"] = test[\"onpromotion\"].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1782 [00:00<?, ?it/s]15:23:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:23:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "/var/folders/g6/ld3hdqzj3d7840n3yw1hgcjc0000gn/T/ipykernel_13174/3559865377.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  submission = pd.concat([submission, cleaned_test_subset])\n",
      "  0%|          | 2/1782 [00:00<08:54,  3.33it/s]15:23:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:23:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 3/1782 [00:00<09:24,  3.15it/s]15:23:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:23:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 4/1782 [00:01<11:07,  2.66it/s]15:23:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:23:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 5/1782 [00:01<11:05,  2.67it/s]15:24:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 6/1782 [00:02<11:41,  2.53it/s]15:24:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 7/1782 [00:02<11:25,  2.59it/s]15:24:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  0%|          | 8/1782 [00:02<11:17,  2.62it/s]15:24:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 9/1782 [00:03<11:29,  2.57it/s]15:24:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 10/1782 [00:03<11:21,  2.60it/s]15:24:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 11/1782 [00:04<11:20,  2.60it/s]15:24:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 12/1782 [00:04<11:18,  2.61it/s]15:24:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 13/1782 [00:04<11:11,  2.63it/s]15:24:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 14/1782 [00:05<11:11,  2.63it/s]15:24:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 15/1782 [00:05<10:53,  2.70it/s]15:24:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 16/1782 [00:06<10:49,  2.72it/s]15:24:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 17/1782 [00:06<11:00,  2.67it/s]15:24:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 18/1782 [00:06<11:04,  2.66it/s]15:24:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 19/1782 [00:07<11:39,  2.52it/s]15:24:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 20/1782 [00:07<11:28,  2.56it/s]15:24:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 21/1782 [00:08<11:47,  2.49it/s]15:24:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|          | 22/1782 [00:08<11:32,  2.54it/s]15:24:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|▏         | 23/1782 [00:08<11:05,  2.64it/s]15:24:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|▏         | 24/1782 [00:09<11:40,  2.51it/s]15:24:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|▏         | 25/1782 [00:09<11:22,  2.58it/s]15:24:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  1%|▏         | 26/1782 [00:09<11:03,  2.65it/s]15:24:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 27/1782 [00:10<10:49,  2.70it/s]15:24:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 28/1782 [00:10<11:28,  2.55it/s]15:24:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 29/1782 [00:11<11:34,  2.53it/s]15:24:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 30/1782 [00:11<12:19,  2.37it/s]15:24:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 31/1782 [00:12<12:37,  2.31it/s]15:24:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 32/1782 [00:12<11:59,  2.43it/s]15:24:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 33/1782 [00:12<11:24,  2.55it/s]15:24:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 34/1782 [00:13<11:13,  2.59it/s]15:24:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 35/1782 [00:13<11:14,  2.59it/s]15:24:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 36/1782 [00:13<10:49,  2.69it/s]15:24:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 38/1782 [00:14<09:38,  3.01it/s]15:24:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 39/1782 [00:14<10:28,  2.78it/s]15:24:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 40/1782 [00:15<10:19,  2.81it/s]15:24:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 41/1782 [00:15<10:43,  2.70it/s]15:24:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 42/1782 [00:16<11:47,  2.46it/s]15:24:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 43/1782 [00:16<11:16,  2.57it/s]15:24:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  2%|▏         | 44/1782 [00:16<11:03,  2.62it/s]15:24:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  3%|▎         | 45/1782 [00:17<11:18,  2.56it/s]15:24:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "  3%|▎         | 45/1782 [00:17<11:18,  2.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/store-sales/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'floor'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     30\u001b[0m future \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmake_future_dataframe(\n\u001b[1;32m     31\u001b[0m     periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_subset), include_history\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m forecast \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(future)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Store the predictions\u001b[39;00m\n\u001b[1;32m     36\u001b[0m test_subset \u001b[38;5;241m=\u001b[39m test_subset\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniconda/envs/store-sales/lib/python3.11/site-packages/prophet/forecaster.py:1270\u001b[0m, in \u001b[0;36mProphet.predict\u001b[0;34m(self, df, vectorized)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataframe has no rows.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1270\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_dataframe(df\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[1;32m   1272\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_trend(df)\n\u001b[1;32m   1273\u001b[0m seasonal_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_seasonal_components(df)\n",
      "File \u001b[0;32m~/miniconda/envs/store-sales/lib/python3.11/site-packages/prophet/forecaster.py:333\u001b[0m, in \u001b[0;36mProphet.setup_dataframe\u001b[0;34m(self, df, initialize_scales)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 333\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    335\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_min\n",
      "File \u001b[0;32m~/miniconda/envs/store-sales/lib/python3.11/site-packages/pandas/core/frame.py:4091\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4088\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4090\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4091\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[0;32m~/miniconda/envs/store-sales/lib/python3.11/site-packages/pandas/core/frame.py:4314\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4311\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   4312\u001b[0m             refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_mgr(key, value, refs)\n",
      "File \u001b[0;32m~/miniconda/envs/store-sales/lib/python3.11/site-packages/pandas/core/frame.py:4261\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value, refs)\u001b[0m\n\u001b[1;32m   4257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item_mgr\u001b[39m(\n\u001b[1;32m   4258\u001b[0m     \u001b[38;5;28mself\u001b[39m, key, value: ArrayLike, refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4259\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4260\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4261\u001b[0m         loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4262\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   4263\u001b[0m         \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[1;32m   4264\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis), key, value, refs)\n",
      "File \u001b[0;32m~/miniconda/envs/store-sales/lib/python3.11/site-packages/pandas/core/indexes/base.py:3794\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m-> 3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m   3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m<frozen abc>:119\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "# Train a Prophet model for each store and product family\n",
    "submission = pd.DataFrame(columns=[\"id\", \"sales\"])\n",
    "\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\n",
    "\n",
    "stores = train[\"store_nbr\"].unique()\n",
    "families = train[\"family\"].unique()\n",
    "# stores = [1]\n",
    "# families = [\"AUTOMOTIVE\"]\n",
    "for store, family in tqdm(list(itertools.product(stores, families))):\n",
    "    # Filter the data for the current store and product family\n",
    "    train_subset = train[(train[\"store_nbr\"] == store) & (train[\"family\"] == family)]\n",
    "    test_subset = test[(test[\"store_nbr\"] == store) & (test[\"family\"] == family)]\n",
    "\n",
    "    # Prepare the data for Prophet\n",
    "    prophet_data = train_subset[[\"date\", \"sales\"]].copy()\n",
    "    prophet_data.rename(columns={\"date\": \"ds\", \"sales\": \"y\"}, inplace=True)\n",
    "\n",
    "    # Initialize and fit the model\n",
    "    model = Prophet(holidays=holidays.copy())\n",
    "    model.fit(prophet_data)\n",
    "\n",
    "    # Make predictions\n",
    "    future = model.make_future_dataframe(\n",
    "        periods=len(test_subset), include_history=False\n",
    "    )\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Store the predictions\n",
    "    test_subset = test_subset.copy()\n",
    "    test_subset[\"sales\"] = forecast[\"yhat\"].values\n",
    "\n",
    "    cleaned_test_subset = test_subset[[\"id\", \"sales\"]].dropna(axis=1, how=\"all\")\n",
    "    submission = pd.concat([submission, cleaned_test_subset])\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "store-sales",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
